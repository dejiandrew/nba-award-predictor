{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b81043c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No existing DataFrame found in memory\n",
      "Downloading files...\n",
      "\n",
      "Downloaded playerstatistics.csv\n",
      "Processing data in chunks of 100000 rows...\n",
      "Processed chunk 1 - Total rows: 100000\n",
      "Processed chunk 2 - Total rows: 200000\n",
      "Processed chunk 3 - Total rows: 300000\n",
      "Processed chunk 4 - Total rows: 400000\n",
      "Processed chunk 5 - Total rows: 500000\n",
      "Processed chunk 6 - Total rows: 600000\n",
      "Processed chunk 7 - Total rows: 700000\n",
      "Processed chunk 8 - Total rows: 800000\n",
      "Processed chunk 9 - Total rows: 900000\n",
      "Processed chunk 10 - Total rows: 1000000\n",
      "Processed chunk 11 - Total rows: 1100000\n",
      "Processed chunk 12 - Total rows: 1200000\n",
      "Processed chunk 13 - Total rows: 1300000\n",
      "Processed chunk 14 - Total rows: 1400000\n",
      "Processed chunk 15 - Total rows: 1500000\n",
      "Processed chunk 16 - Total rows: 1600000\n",
      "Processed chunk 17 - Total rows: 1634609\n",
      "All chunks processed. Total rows: 1634609\n",
      "Results saved to player-statistics.csv\n",
      "Uploading file to Google Cloud Storage...\n",
      "File successfully uploaded to gs://nba_award_predictor/nba_data/player-statistics.csv\n",
      "Uploaded file size: 315.22 MB\n",
      "Process complete!\n"
     ]
    }
   ],
   "source": [
    "# First, clear any existing large DataFrames from memory\n",
    "try:\n",
    "    del player_statistics_df\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    print(\"Memory cleared from previous DataFrame\")\n",
    "except NameError:\n",
    "    print(\"No existing DataFrame found in memory\")\n",
    "\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import re\n",
    "import duckdb\n",
    "import wget\n",
    "from google.cloud import storage\n",
    "import os\n",
    "\n",
    "def remove_accents(text):\n",
    "    \"\"\"\n",
    "    Remove accent marks from input text while preserving the base characters.\n",
    "    Also handles special characters like Đ/đ.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "        \n",
    "    special_chars = {\n",
    "        'Đ': 'D', 'đ': 'd', 'Ł': 'L', 'ł': 'l', 'Ø': 'O', 'ø': 'o',\n",
    "        'Ŧ': 'T', 'ŧ': 't', 'Æ': 'AE', 'æ': 'ae', 'Œ': 'OE', 'œ': 'oe',\n",
    "        'ß': 'ss'\n",
    "    }\n",
    "    \n",
    "    for char, replacement in special_chars.items():\n",
    "        text = text.replace(char, replacement)\n",
    "    \n",
    "    normalized_text = unicodedata.normalize('NFKD', text)\n",
    "    result = ''.join(c for c in normalized_text if not unicodedata.category(c).startswith('Mn'))\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Download files\n",
    "print(\"Downloading files...\")\n",
    "filename = 'playerstatistics.csv'\n",
    "url = f'https://storage.googleapis.com/nba_award_predictor/nba_data/{filename}'\n",
    "wget.download(url)\n",
    "print(f\"\\nDownloaded {filename}\")\n",
    "\n",
    "# filename = 'name_mappings.csv?authuser=4'\n",
    "# url = f'https://storage.googleapis.com/nba_award_predictor/nba_data/{filename}'\n",
    "# wget.download(url)\n",
    "# print(f\"\\nDownloaded name_mappings.csv\")\n",
    "\n",
    "# filename = 'nba_player_lookup.csv'\n",
    "# url = f'https://storage.googleapis.com/nba_award_predictor/nba_data/{filename}'\n",
    "# wget.download(url)\n",
    "# print(f\"\\nDownloaded {filename}\")\n",
    "\n",
    "# # Read in the smaller datasets fully\n",
    "# name_mapping_df = pd.read_csv('name_mappings.csv')\n",
    "# nba_player_lookup_df = pd.read_csv('nba_player_lookup.csv')\n",
    "\n",
    "# # Clean player names in lookup table\n",
    "# nba_player_lookup_df[\"player_name\"] = nba_player_lookup_df[\"player_name\"].apply(remove_accents)\n",
    "\n",
    "# # Register these dataframes with DuckDB\n",
    "# duckdb.register('name_mapping_df', name_mapping_df)\n",
    "# duckdb.register('nba_player_lookup_df', nba_player_lookup_df)\n",
    "\n",
    "# Define the output file\n",
    "output_file = 'player-statistics.csv'\n",
    "\n",
    "# Process and save in chunks\n",
    "chunk_size = 100000\n",
    "first_chunk = True\n",
    "processed_rows = 0\n",
    "\n",
    "print(f\"Processing data in chunks of {chunk_size} rows...\")\n",
    "\n",
    "for chunk_num, chunk in enumerate(pd.read_csv('playerstatistics.csv', chunksize=chunk_size, low_memory=False)):\n",
    "    # Add full_name column\n",
    "    chunk['full_name'] = chunk['firstName'] + ' ' + chunk['lastName']\n",
    "    \n",
    "    # Register current chunk with DuckDB\n",
    "    duckdb.register('player_statistics_chunk', chunk)\n",
    "    \n",
    "    query = \"\"\"\n",
    "    SELECT\n",
    "    firstName\n",
    "    ,lastName\n",
    "    ,full_name\n",
    "    ,personId AS player_id\n",
    "    ,gameId\n",
    "    ,gameDate\n",
    "    ,playerteamCity\n",
    "    ,playerteamName\n",
    "    ,opponentteamCity\n",
    "    ,opponentteamName\n",
    "    ,gameType\n",
    "    ,gameLabel\n",
    "    ,gameSubLabel\n",
    "    ,seriesGameNumber\n",
    "    ,win\n",
    "    ,home\n",
    "    ,numMinutes\n",
    "    ,points\n",
    "    ,assists\n",
    "    ,blocks\n",
    "    ,steals\n",
    "    ,fieldGoalsAttempted\n",
    "    ,fieldGoalsMade\n",
    "    ,fieldGoalsPercentage\n",
    "    ,threePointersAttempted\n",
    "    ,threePointersMade\n",
    "    ,threePointersPercentage\n",
    "    ,freeThrowsAttempted\n",
    "    ,freeThrowsMade\n",
    "    ,freeThrowsPercentage\n",
    "    ,reboundsDefensive\n",
    "    ,reboundsOffensive\n",
    "    ,reboundsTotal\n",
    "    ,foulsPersonal\n",
    "    ,turnovers\n",
    "    ,plusMinusPoints\n",
    "    FROM player_statistics_chunk\n",
    "    \"\"\"\n",
    "    \n",
    "    # Execute query for this chunk\n",
    "    result_chunk = duckdb.query(query).df()\n",
    "\n",
    "    # Drop any rows where player_id is null then convert player_id column from float to int. \n",
    "    result_chunk = result_chunk.dropna(subset=['player_id'])\n",
    "    result_chunk[\"player_id\"] = result_chunk[\"player_id\"].astype('Int64')\n",
    "    \n",
    "    # Write to CSV (first chunk with header, subsequent chunks without)\n",
    "    if first_chunk:\n",
    "        result_chunk.to_csv(output_file, index=False, mode='w')\n",
    "        first_chunk = False\n",
    "    else:\n",
    "        result_chunk.to_csv(output_file, index=False, mode='a', header=False)\n",
    "    \n",
    "    # Update progress\n",
    "    processed_rows += len(result_chunk)\n",
    "    print(f\"Processed chunk {chunk_num+1} - Total rows: {processed_rows}\")\n",
    "    \n",
    "    # Clean up to free memory\n",
    "    duckdb.unregister('player_statistics_chunk')\n",
    "    del chunk\n",
    "    del result_chunk\n",
    "\n",
    "print(f\"All chunks processed. Total rows: {processed_rows}\")\n",
    "print(f\"Results saved to {output_file}\")\n",
    "\n",
    "# Upload to GCS\n",
    "print(\"Uploading file to Google Cloud Storage...\")\n",
    "\n",
    "# Path to your credentials file\n",
    "credentials_path = 'cis-5450-final-project-485661e2f371.json'\n",
    "\n",
    "try:\n",
    "    # Set up the client with your credentials\n",
    "    storage_client = storage.Client.from_service_account_json(credentials_path)\n",
    "    \n",
    "    # Specify your bucket name\n",
    "    bucket_name = 'nba_award_predictor'\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    \n",
    "    # Define blob (file in GCS) and upload from the local file\n",
    "    blob = bucket.blob('nba_data/player-statistics.csv')\n",
    "    blob.cache_control = \"max-age=0\"\n",
    "    blob.upload_from_filename(output_file)\n",
    "    \n",
    "    print(f\"File successfully uploaded to gs://{bucket_name}/nba_data/player-statistics.csv\")\n",
    "    \n",
    "    # Get file size for confirmation\n",
    "    file_size_mb = os.path.getsize(output_file) / (1024 * 1024)\n",
    "    print(f\"Uploaded file size: {file_size_mb:.2f} MB\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error uploading to GCS: {e}\")\n",
    "    print(\"You may need to update the credentials file.\")\n",
    "\n",
    "# URL of the final CSV file\n",
    "filename = 'player-statistics.csv'\n",
    "url = f'https://storage.googleapis.com/nba_award_predictor/nba_data/{filename}'\n",
    "wget.download(url)\n",
    "# Read in the player-statistics csv (comment this out if deploying on remote server, to save RAM)\n",
    "#player_statistics_df = pd.read_csv(filename)\n",
    "\n",
    "os.remove(\"player-statistics.csv\")\n",
    "os.remove(\"playerstatistics.csv\")\n",
    "# os.remove(\"name_mappings.csv\")\n",
    "# os.remove(\"nba_player_lookup.csv\")\n",
    "os.remove(\"player-statistics (1).csv\")\n",
    "\n",
    "print(\"Process complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521a3d10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
