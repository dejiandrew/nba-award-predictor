{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "784b2998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['firstName', 'lastName', 'personId', 'gameId', 'gameDate',\n",
       "       'playerteamCity', 'playerteamName', 'opponentteamCity',\n",
       "       'opponentteamName', 'gameType', 'gameLabel', 'gameSubLabel',\n",
       "       'seriesGameNumber', 'win', 'home', 'numMinutes', 'points', 'assists',\n",
       "       'blocks', 'steals', 'fieldGoalsAttempted', 'fieldGoalsMade',\n",
       "       'fieldGoalsPercentage', 'threePointersAttempted', 'threePointersMade',\n",
       "       'threePointersPercentage', 'freeThrowsAttempted', 'freeThrowsMade',\n",
       "       'freeThrowsPercentage', 'reboundsDefensive', 'reboundsOffensive',\n",
       "       'reboundsTotal', 'foulsPersonal', 'turnovers', 'plusMinusPoints'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player_statistics_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87f46c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_147093/3532353106.py:45: DtypeWarning: Columns (10,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  player_statistics_df = pd.read_csv(filename)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import unicodedata\n",
    "import re\n",
    "import duckdb\n",
    "import requests\n",
    "from io import StringIO\n",
    "from google.cloud import storage\n",
    "import wget\n",
    "\n",
    "def remove_accents(text):\n",
    "    \"\"\"\n",
    "    Remove accent marks from input text while preserving the base characters.\n",
    "    Also handles special characters like Đ/đ.\n",
    "    \n",
    "    Example:\n",
    "    \"Nikola Đurišić\" -> \"Nikola Durisic\"\n",
    "    \"\"\"\n",
    "    # First, handle special characters that need specific replacements\n",
    "    special_chars = {\n",
    "        'Đ': 'D', 'đ': 'd',  # Serbian/Croatian D with stroke\n",
    "        'Ł': 'L', 'ł': 'l',  # Polish L with stroke\n",
    "        'Ø': 'O', 'ø': 'o',  # Danish/Norwegian O with stroke\n",
    "        'Ŧ': 'T', 'ŧ': 't',  # Sami T with stroke\n",
    "        'Æ': 'AE', 'æ': 'ae',  # Æ/æ ligature\n",
    "        'Œ': 'OE', 'œ': 'oe',  # Œ/œ ligature\n",
    "        'ß': 'ss',  # German eszett\n",
    "    }\n",
    "    \n",
    "    for char, replacement in special_chars.items():\n",
    "        text = text.replace(char, replacement)\n",
    "    \n",
    "    # Normalize the text to decompose characters into base character and accent mark\n",
    "    normalized_text = unicodedata.normalize('NFKD', text)\n",
    "    \n",
    "    # Filter out the non-spacing marks (accent marks)\n",
    "    result = ''.join(c for c in normalized_text if not unicodedata.category(c).startswith('Mn'))\n",
    "    \n",
    "    return result\n",
    "\n",
    "# URL of the CSV file\n",
    "filename = 'playerstatistics.csv'\n",
    "url = f'https://storage.googleapis.com/nba_award_predictor/nba_data/{filename}'\n",
    "wget.download(url)\n",
    "# Read in the playerstatistics csv\n",
    "player_statistics_df = pd.read_csv(filename)\n",
    "\n",
    "# Clean each player's full name\n",
    "#player_statistics_df[\"display_first_last\"] = player_statistics_df[\"display_first_last\"].apply(remove_accents)\n",
    "\n",
    "# Bring in name mapping table for names to help match all names to the format seen in the NBA API\n",
    "filename = 'name_mappings.csv'\n",
    "url = f'https://storage.googleapis.com/nba_award_predictor/nba_data/{filename}'\n",
    "wget.download(url)\n",
    "# Read in the name_mappings csv\n",
    "name_mapping_df = pd.read_csv(filename)\n",
    "\n",
    "# Bring in nba player lookup table to map the cleaned names to player IDs. Same player IDs from the NBA API.\n",
    "filename = 'nba_player_lookup.csv'\n",
    "url = f'https://storage.googleapis.com/nba_award_predictor/nba_data/{filename}'\n",
    "wget.download(url)\n",
    "# Read in the nba_player_lookup csv\n",
    "nba_player_lookup_df = pd.read_csv(filename)\n",
    "\n",
    "# Clean each player's full name\n",
    "nba_player_lookup_df[\"player_name\"] = nba_player_lookup_df[\"player_name\"].apply(remove_accents)\n",
    "\n",
    "# Create a new column for full name\n",
    "player_statistics_df['full_name'] = player_statistics_df['firstName'].str.cat(player_statistics_df['lastName'], sep=' ')\n",
    "\n",
    "\n",
    "query = \"\"\"\n",
    "\n",
    "WITH CTE AS (\n",
    "SELECT * FROM player_statistics_df\n",
    "LEFT JOIN name_mapping_df\n",
    "ON player_statistics_df.full_name = name_mapping_df.in_table_name\n",
    ")\n",
    ",CTE2 AS (\n",
    "SELECT *,\n",
    "CASE WHEN nba_lookup_name IS NULL THEN full_name\n",
    "ELSE nba_lookup_name\n",
    "END AS player_full_name\n",
    "FROM CTE\n",
    ")\n",
    "\n",
    "SELECT CTE2.*\n",
    ",nba_player_lookup_df.player_id\n",
    "FROM CTE2\n",
    "LEFT JOIN nba_player_lookup_df\n",
    "ON CTE2.player_full_name = nba_player_lookup_df.player_name\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "player_statistics_df = duckdb.query(query).df()\n",
    "player_statistics_df\n",
    "\n",
    "#Rearrange columns\n",
    "# cols = common_player_info_df.columns.tolist()\n",
    "# new_cols = [cols[-1], cols[-2]] + cols[:-2]\n",
    "# common_player_info_df = common_player_info_df[new_cols]\n",
    "# common_player_info_df.to_csv('common-player-info.csv')\n",
    "\n",
    "\n",
    "# # Path to your credentials file\n",
    "# credentials_path = 'cis-5450-final-project-485661e2f371.json'\n",
    "\n",
    "# # Set up the client with your credentials\n",
    "# storage_client = storage.Client.from_service_account_json(credentials_path)\n",
    "\n",
    "# # Specify your bucket name\n",
    "# bucket_name = 'nba_award_predictor'\n",
    "# bucket = storage_client.bucket(bucket_name)\n",
    "\n",
    "# # Define blob (file in GCS) and upload from the local file\n",
    "# blob = bucket.blob('nba_data/common-player-info.csv')\n",
    "# blob.cache_control = \"max-age=0\"\n",
    "# blob.upload_from_filename('common-player-info.csv')\n",
    "\n",
    "# print(f\"File uploaded to gs://{bucket_name}/nba_data/common-player-info.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02511ea7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
